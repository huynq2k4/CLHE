pog:
  data_path: './datasets/'
  batch_size_train: 256 # the batch size for training
  batch_size_test: 1024 # the batch size for testing
  topk: [5, 10, 20, 40, 80] # the topks metrics for evaluation
  neg_num: 1 # number of negatives used for BPR loss. All the experiments use 1.
  embedding_sizes: [64] # the embedding size for user, bundle, and item
  num_layerss: [1] # number of layers for the infomation progagation over the item- and bundle-level graphs
  lrs: [1.0e-3] # learning rate
  l2_regs: [1.0e-5] # the l2 regularization weight: lambda_2
  epochs: 50 # number of epochs to train
  test_interval: 2 # by how many epochs to run the validation and testing.

pog_dense:
  data_path: './datasets/'
  batch_size_train: 256 # the batch size for training
  batch_size_test: 1024 # the batch size for testing
  topk: [5, 10, 20, 40, 80] # the topks metrics for evaluation
  neg_num: 1 # number of negatives used for BPR loss. All the experiments use 1.
  embedding_sizes: [64] # the embedding size for user, bundle, and item
  num_layerss: [1] # number of layers for the infomation progagation over the item- and bundle-level graphs
  lrs: [1.0e-3] # learning rate
  l2_regs: [1.0e-5] # the l2 regularization weight: lambda_2
  epochs: 50 # number of epochs to train
  test_interval: 2 # by how many epochs to run the validation and testing.

spotify:
  data_path: './datasets/'
  batch_size_train: 256 # the batch size for training
  batch_size_test: 256 # the batch size for testing
  topk: [10, 20, 40, 80] # the topks metrics for evaluation
  neg_num: 1 # number of negatives used for BPR loss. All the experiments use 1.
  embedding_sizes: [64] # the embedding size for user, bundle, and item
  num_layerss: [1] # number of layers for the infomation progagation over the item- and bundle-level graphs
  lrs: [1.0e-3] # learning rate
  l2_regs: [1.0e-5] # the l2 regularization weight: lambda_2
  epochs: 100 # number of epochs to train # default: 100
  test_interval: 2 # by how many epochs to run the validation and testing.

spotify_sparse:
  data_path: './datasets/'
  batch_size_train: 256 # the batch size for training
  batch_size_test: 256 # the batch size for testing
  topk: [10, 20, 40, 80] # the topks metrics for evaluation
  neg_num: 1 # number of negatives used for BPR loss. All the experiments use 1.
  embedding_sizes: [64] # the embedding size for user, bundle, and item
  num_layerss: [1] # number of layers for the infomation progagation over the item- and bundle-level graphs
  lrs: [1.0e-3] # learning rate
  l2_regs: [1.0e-5] # the l2 regularization weight: lambda_2
  epochs: 100 # number of epochs to train # default: 100
  test_interval: 2 # by how many epochs to run the validation and testing.
  